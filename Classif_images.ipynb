{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "from PIL import Image,ImageOps\n",
    "import PIL\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path += '\\\\101_ObjectCategories'\n",
    "contents = os.listdir(path)\n",
    "name_tags = {k: v for v, k in enumerate(contents)} # conver to dict of names:indices\n",
    "reverse_of_name_tags = {v: k for v, k in enumerate(contents)}# reverse dictionary for future use\\\n",
    "Data = []\n",
    "image_shape = (512 , 512)\n",
    "dropoutVec = [1.0] * 8 + [0.7] * 2 + [0.5] * 2 + [0.5] * 1 + [0.5, 1.] * 5\n",
    "learningRate=0.002\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "batchSize = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseheight = 560\n",
    "\n",
    "for folder in contents: # read Data \n",
    "    folder_contents=os.listdir(path+\"\\\\\"+folder)\n",
    "    for file in folder_contents:\n",
    "        img = Image.open(path+\"\\\\\"+folder+\"\\\\\"+file)\n",
    "        img = ImageOps.fit(img, image_shape, Image.ANTIALIAS)\n",
    "        image= np.array(img)\n",
    "        #print(image.shape)\n",
    "        #plt.imshow(image)\n",
    "        if image.shape == (512,512 ,3): # remove some irregular images\n",
    "            Data.append([image , name_tags[folder]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate data \n",
    "X = [x[0] for x in Data]\n",
    "Y = [y[1] for y in Data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(range(total_files))\n",
    "random.shuffle(indices)\n",
    "train_indices = indices[:int(0.8*total_files)]\n",
    "test_indices = indices[int(0.8*total_files):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain = np.array([(X[i]) for i in train_indices]),np.array([Y[i] for i in train_indices]) \n",
    "Xtest,Ytest = np.array([X[i] for i in test_indices]),np.array([Y[i] for i in test_indices]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain[152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(inputs=Xtrain, targets = Ytrain , batchSize = 200):\n",
    "    batchX = np.zeros((batchSize, image_shape[0],image_shape[1],3 ))    \n",
    "    batchY = np.zeros((batchSize, 1))\n",
    "    idx = 0       \n",
    "    while True: # to make sure we never reach the end\n",
    "        counter = 0\n",
    "        while counter<=batchSize-1:\n",
    "            dataIdx = np.random.randint(batchSize-1) \n",
    "            batchX[counter] = inputs[dataIdx]\n",
    "            batchY[counter] = targets[dataIdx]\n",
    "            counter += 1\n",
    "        yield (batchX, batchY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_ones(shape, name):\n",
    "    initial = tf.constant(1.0, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def weight_xavi_init(shape, name):\n",
    "    initial = tf.get_variable(name=name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return initial\n",
    "\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, dropout, image_shape):\n",
    "        \"\"\" We put a few counters to see how many times we called each function \"\"\"\n",
    "        self._dropout_vec = dropout\n",
    "        self._image_shape = image_shape\n",
    "        self._count_conv = 0\n",
    "        self._count_pool = 0\n",
    "        self._count_bn = 0\n",
    "        self._count_activations = 0\n",
    "        self._count_dropouts = 0\n",
    "        self._count_fc = 0\n",
    "        self._count_lstm = 0\n",
    "        self._count_soft_max = 0\n",
    "        self._conv_kernels = []\n",
    "        self._conv_strides = []\n",
    "        self._weights = {}\n",
    "        self._features = {}\n",
    "\n",
    "    \"\"\" Our conv is currently using bias \"\"\"\n",
    "\n",
    "    def conv(self, x, kernel_size, stride, output_size, padding_in='SAME'):\n",
    "        self._count_conv += 1\n",
    "\n",
    "        filters_in = x.get_shape()[-1]\n",
    "        shape = [kernel_size, kernel_size, filters_in, output_size]\n",
    "\n",
    "        weights = weight_xavi_init(shape, 'W_c_' + str(self._count_conv))\n",
    "        bias = bias_variable([output_size], name='B_c_' + str(self._count_conv))\n",
    "\n",
    "        self._weights['W_conv' + str(self._count_conv)] = weights\n",
    "        self._conv_kernels.append(kernel_size)\n",
    "        self._conv_strides.append(stride)\n",
    "\n",
    "        conv_res = tf.add(tf.nn.conv2d(x, weights, [1, stride, stride, 1], padding=padding_in,\n",
    "                                       name='conv2d_' + str(self._count_conv)), bias,\n",
    "                          name='add_' + str(self._count_conv))\n",
    "\n",
    "        self._features['conv_block' + str(self._count_conv - 1)] = conv_res\n",
    "\n",
    "        return conv_res\n",
    "\n",
    "    def max_pool(self, x, ksize=3, stride=2):\n",
    "        self._count_pool += 1\n",
    "        return tf.nn.max_pool(x, ksize=[1, ksize, ksize, 1], strides=[1, stride, stride, 1],\n",
    "                              padding='SAME', name='max_pool' + str(self._count_pool))\n",
    "\n",
    "    def bn(self, x):\n",
    "        self._count_bn += 1\n",
    "        return tf.contrib.layers.batch_norm(x, is_training=False,\n",
    "                                            updates_collections=None, scope='bn' + str(self._count_bn))\n",
    "\n",
    "    def activation(self, x):\n",
    "        self._count_activations += 1\n",
    "        return tf.nn.relu(x, name='relu' + str(self._count_activations))\n",
    "\n",
    "    def dropout(self, x):\n",
    "        print (\"Dropout\", self._count_dropouts)\n",
    "        self._count_dropouts += 1\n",
    "        output = tf.nn.dropout(x, self._dropout_vec[self._count_dropouts - 1],\n",
    "                               name='dropout' + str(self._count_dropouts))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def fc(self, x, output_size):\n",
    "        self._count_fc += 1\n",
    "        filters_in = x.get_shape()[-1]\n",
    "        shape = [filters_in, output_size]\n",
    "\n",
    "        weights = weight_xavi_init(shape, 'W_f_' + str(self._count_fc))\n",
    "        bias = bias_variable([output_size], name='B_f_' + str(self._count_fc))\n",
    "\n",
    "        return tf.nn.xw_plus_b(x, weights, bias, name='fc_' + str(self._count_fc))\n",
    "\n",
    "    def conv_block(self, x, kernel_size, stride, output_size, padding_in='SAME'):\n",
    "        print( \" === Conv\", self._count_conv, \"  :  \", kernel_size, stride, output_size)\n",
    "        with tf.name_scope(\"conv_block\" + str(self._count_conv)):\n",
    "            x = self.conv(x, kernel_size, stride, output_size, padding_in=padding_in)\n",
    "            x = self.bn(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            return self.activation(x)\n",
    "\n",
    "    def fc_block(self, x, output_size):\n",
    "        print (\" === FC\", self._count_fc, \"  :  \", output_size)\n",
    "        with tf.name_scope(\"fc\" + str(self._count_fc + 1)):\n",
    "            x = self.fc(x, output_size)\n",
    "            x = self.dropout(x)\n",
    "            self._features['fc_block' + str(self._count_fc + 1)] = x\n",
    "            return self.activation(x)\n",
    "\n",
    "    def get_weigths_dict(self):\n",
    "        return self._weights\n",
    "\n",
    "    def get_feat_tensors_dict(self):\n",
    "        return self._features\n",
    "def load_imitation_learning_network(input_image, dropout):\n",
    "    x = input_image\n",
    "    network_manager = Network(dropout, tf.shape(x))\n",
    "    with tf.name_scope(\"ConvNet\"):\n",
    "        \"\"\"conv1\"\"\"  # kernel sz, stride, num feature maps\n",
    "        xc = network_manager.conv_block(x, 5, 2, 32, padding_in='VALID')\n",
    "        print( xc)\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 32, padding_in='VALID')\n",
    "        print(xc)\n",
    "\n",
    "        \"\"\"conv2\"\"\"\n",
    "        xc = network_manager.conv_block(xc, 3, 2, 64, padding_in='VALID')\n",
    "        print(xc)\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 64, padding_in='VALID')\n",
    "        print(xc)\n",
    "\n",
    "        \"\"\"conv3\"\"\"\n",
    "        xc = network_manager.conv_block(xc, 3, 2, 128, padding_in='VALID')\n",
    "        print(xc)\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 128, padding_in='VALID')\n",
    "        print(xc)\n",
    "\n",
    "        \"\"\"conv4\"\"\"\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 256, padding_in='VALID')\n",
    "        print(xc)\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 256, padding_in='VALID')\n",
    "        print(xc)\n",
    "        \"\"\"mp3 (default values)\"\"\"\n",
    "\n",
    "        \"\"\" reshape \"\"\"\n",
    "        x = tf.reshape(xc, [-1, int(np.prod(xc.get_shape()[1:]))], name='reshape')\n",
    "        print (x)\n",
    "\n",
    "        \"\"\" fc1 \"\"\"\n",
    "        x = network_manager.fc_block(x, 512)\n",
    "        print (x)\n",
    "        \"\"\" fc2 \"\"\"\n",
    "        x = network_manager.fc_block(x, 512)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlNet(inputs, targets, shape, dropoutVec, scopeName = 'controlNET'):\n",
    "    \"\"\"\n",
    "        Get one image/sequence of images to predict control operations for controling the vehicle\n",
    "        inputs: N Batch of M images in order\n",
    "        shape: [BatchSize, SeqSize, FrameHeight, FrameWeight, Channels]\n",
    "        phase: placeholder for training\n",
    "        scopeName: TensorFlow Scope Name to separate nets in the graph\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scopeName) as scope:\n",
    "        with tf.name_scope(\"Network\"):           \n",
    "            networkTensor = load_imitation_learning_network(inputs[0], dropoutVec)\n",
    "            solverList = []\n",
    "            lossList = []\n",
    "            trainVars = tf.trainable_variables()\n",
    "            with tf.name_scope(\"ConvNet\"):             \n",
    "                contLoss = tf.reduce_mean(tf.square(tf.subtract(networkTensor, targets[0]))) #+ tf.add_n([tf.nn.l2_loss(v) for v in trainVars]) * L2NormConst\n",
    "                contSolver = tf.train.AdamOptimizer(learning_rate=learningRate, beta1=beta1,\n",
    "                                                    beta2=beta2).minimize(contLoss)\n",
    "                solverList.append(contSolver)\n",
    "                lossList.append(contLoss)  \n",
    "                tf.summary.scalar(\"ConVnet_output\", contLoss)        \n",
    "        tensors = {\n",
    "            'optimizers' : solverList,\n",
    "            'losses' : lossList,\n",
    "            'output' : networkTensor\n",
    "        }\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Net( prefSize=(image_shape[0], image_shape[1], 3)):   \n",
    "    shapeInput = [None, prefSize[0], prefSize[1], prefSize[2]]\n",
    "    inputImages = tf.placeholder(\"float\", shape=[None, prefSize[0], prefSize[1],\n",
    "                                                                 prefSize[2]], name=\"input_image\")      \n",
    "    inputs = [inputImages]\n",
    "    dout = tf.placeholder(\"float\", shape=len(dropoutVec)) \n",
    "    targettag = tf.placeholder(tf.float32, shape=[None, 1], name=\"target_speed\")   \n",
    "    targets = [targettag]\n",
    "    print('Building ControlNet ...')    \n",
    "    controlOpTensors = controlNet(inputs, targets, shapeInput, dout,scopeName = 'controlNET')   \n",
    "    tensors = {\n",
    "            'inputs' : inputs,\n",
    "            'targets' : targets,\n",
    "            'dropoutVec' : dout,\n",
    "            'output' : controlOpTensors\n",
    "    }\n",
    "    return tensors # [ inputs['inputImages','inputData'], targets['targetSpeed', 'targetController'],  'params', dropoutVec', output[optimizers, losses, branchesOutputs] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Net ...\n",
      "Building ControlNet ...\n",
      " === Conv 0   :   5 2 32\n",
      "Dropout 0\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block0/relu1:0\", shape=(?, 254, 254, 32), dtype=float32)\n",
      " === Conv 1   :   3 1 32\n",
      "Dropout 1\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block1/relu2:0\", shape=(?, 252, 252, 32), dtype=float32)\n",
      " === Conv 2   :   3 2 64\n",
      "Dropout 2\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block2/relu3:0\", shape=(?, 125, 125, 64), dtype=float32)\n",
      " === Conv 3   :   3 1 64\n",
      "Dropout 3\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block3/relu4:0\", shape=(?, 123, 123, 64), dtype=float32)\n",
      " === Conv 4   :   3 2 128\n",
      "Dropout 4\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block4/relu5:0\", shape=(?, 61, 61, 128), dtype=float32)\n",
      " === Conv 5   :   3 1 128\n",
      "Dropout 5\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block5/relu6:0\", shape=(?, 59, 59, 128), dtype=float32)\n",
      " === Conv 6   :   3 1 256\n",
      "Dropout 6\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block6/relu7:0\", shape=(?, 57, 57, 256), dtype=float32)\n",
      " === Conv 7   :   3 1 256\n",
      "Dropout 7\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block7/relu8:0\", shape=(?, 55, 55, 256), dtype=float32)\n",
      "Tensor(\"controlNET/Network/ConvNet/reshape:0\", shape=(?, 774400), dtype=float32)\n",
      " === FC 0   :   512\n",
      "Dropout 8\n",
      "Tensor(\"controlNET/Network/ConvNet/fc1/relu9:0\", shape=(?, 512), dtype=float32)\n",
      " === FC 1   :   512\n",
      "Dropout 9\n",
      "{'optimizers': [<tf.Operation 'controlNET/Network/ConvNet_1/Adam' type=NoOp>], 'losses': [<tf.Tensor 'controlNET/Network/ConvNet_1/Mean:0' shape=() dtype=float32>], 'output': <tf.Tensor 'controlNET/Network/ConvNet/fc2/relu10:0' shape=(?, 512) dtype=float32>}\n",
      "Initialize Variables in the Graph ...\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[774400,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: controlNET/W_f_1/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@controlNET/W_f_1/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](controlNET/W_f_1/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'controlNET/W_f_1/Initializer/random_uniform/RandomUniform', defined at:\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-3ee135c74e8c>\", line 26, in <module>\n    netTensors = Net(prefSize=(image_shape[0], image_shape[1], 3))\n  File \"<ipython-input-14-7f91c50968f5>\", line 10, in Net\n    controlOpTensors = controlNet(inputs, targets, shapeInput, dout,scopeName = 'controlNET')\n  File \"<ipython-input-13-a5c8ce427936>\", line 11, in controlNet\n    networkTensor = load_imitation_learning_network(inputs[0], dropoutVec)\n  File \"<ipython-input-12-56f4236cc7cb>\", line 145, in load_imitation_learning_network\n    x = network_manager.fc_block(x, 512)\n  File \"<ipython-input-12-56f4236cc7cb>\", line 101, in fc_block\n    x = self.fc(x, output_size)\n  File \"<ipython-input-12-56f4236cc7cb>\", line 84, in fc\n    weights = weight_xavi_init(shape, 'W_f_' + str(self._count_fc))\n  File \"<ipython-input-12-56f4236cc7cb>\", line 6, in weight_xavi_init\n    initial = tf.get_variable(name=name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1467, in get_variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1217, in get_variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 527, in get_variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 481, in _true_getter\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 903, in _get_single_variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2443, in variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2425, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2406, in default_variable_creator\n    constraint=constraint)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 368, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 885, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\initializers.py\", line 145, in _initializer\n    dtype, seed=seed)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 770, in random_uniform\n    name=name)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[774400,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: controlNET/W_f_1/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@controlNET/W_f_1/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](controlNET/W_f_1/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[774400,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: controlNET/W_f_1/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@controlNET/W_f_1/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](controlNET/W_f_1/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3ee135c74e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetTensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Initialize Variables in the Graph ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# initialize variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m# merge all summaries into a single op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mmerged_summary_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[774400,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: controlNET/W_f_1/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@controlNET/W_f_1/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](controlNET/W_f_1/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'controlNET/W_f_1/Initializer/random_uniform/RandomUniform', defined at:\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-3ee135c74e8c>\", line 26, in <module>\n    netTensors = Net(prefSize=(image_shape[0], image_shape[1], 3))\n  File \"<ipython-input-14-7f91c50968f5>\", line 10, in Net\n    controlOpTensors = controlNet(inputs, targets, shapeInput, dout,scopeName = 'controlNET')\n  File \"<ipython-input-13-a5c8ce427936>\", line 11, in controlNet\n    networkTensor = load_imitation_learning_network(inputs[0], dropoutVec)\n  File \"<ipython-input-12-56f4236cc7cb>\", line 145, in load_imitation_learning_network\n    x = network_manager.fc_block(x, 512)\n  File \"<ipython-input-12-56f4236cc7cb>\", line 101, in fc_block\n    x = self.fc(x, output_size)\n  File \"<ipython-input-12-56f4236cc7cb>\", line 84, in fc\n    weights = weight_xavi_init(shape, 'W_f_' + str(self._count_fc))\n  File \"<ipython-input-12-56f4236cc7cb>\", line 6, in weight_xavi_init\n    initial = tf.get_variable(name=name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1467, in get_variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1217, in get_variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 527, in get_variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 481, in _true_getter\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 903, in _get_single_variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2443, in variable\n    aggregation=aggregation)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2425, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2406, in default_variable_creator\n    constraint=constraint)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 368, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 885, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\initializers.py\", line 145, in _initializer\n    dtype, seed=seed)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 770, in random_uniform\n    name=name)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[774400,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: controlNET/W_f_1/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@controlNET/W_f_1/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](controlNET/W_f_1/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sessGraph = tf.Graph()\n",
    "# GPU configuration\n",
    "memory_fraction = 0.25\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.visible_device_list = '0'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "tf.reset_default_graph()\n",
    "sessGraph = tf.Graph()\n",
    "# Prepare data generators\n",
    "batchListGenTrain = []\n",
    "#batchListGenVal = []\n",
    "#batchListName = []\n",
    "\n",
    "with tf.name_scope(\"ConvNet\"):\n",
    "    miniBatchGen = genData(Xtrain,Ytrain ,batchSize = batchSize)\n",
    "    batchListGenTrain.append(miniBatchGen)\n",
    "    #miniBatchGen = genData(Xval,Yval ,batchSize = batchSize)\n",
    "    #batchListGenVal.append(miniBatchGen)\n",
    "      \n",
    "with sessGraph.as_default():\n",
    "    sess = tf.Session(graph=sessGraph, config = config)\n",
    "    with sess.as_default():        \n",
    "        # build model\n",
    "        print('Building Net ...')\n",
    "        netTensors = Net(prefSize=(image_shape[0], image_shape[1], 3))\n",
    "        print(netTensors['output'])\n",
    "        print('Initialize Variables in the Graph ...')\n",
    "        sess.run(tf.global_variables_initializer()) # initialize variables       \n",
    "        # merge all summaries into a single op\n",
    "        merged_summary_op = tf.summary.merge_all()\n",
    "        saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V2)\n",
    "        if not(trainScratch):\n",
    "            saver.restore(sess, \"test/model.ckpt\") # restore trained parameters\n",
    "        # op to write logs to Tensorboard\n",
    "        logsPath = './logs'\n",
    "        modelPath = './test/'\n",
    "        summary_writer = tf.summary.FileWriter(logsPath, graph=sessGraph)\n",
    "        print('Start Training process ...')        \n",
    "        steps = 0\n",
    "        for epoch in range(epochs):\n",
    "            tStartEpoch = time.time()\n",
    "            print(\"Epoch:\", epoch)\n",
    "            iterations = Xtrain.shape[0]\n",
    "            for j in range(iterations):\n",
    "                steps += 1                \n",
    "                xs , ys = next(batchListGenTrain)                   \n",
    "                # augment images                    \n",
    "                contSolver = netTensors['output']['optimizers'][i]#solverList[i]\n",
    "                contLoss = netTensors['output']['losses'][i]#lossList[i]                                           \n",
    "                # [ inputs['inputImages','inputData'], targets['targetSpeed', 'targetController'],  'params', dropoutVec', output[optimizers, losses, branchesOutputs] ]\n",
    "                feedDict = {netTensors['inputs'][0]: xs,  netTensors['dropoutVec']: dropoutVec, \n",
    "                            netTensors['targets']: ys.reshape([batchSize,1]), \n",
    "                            }                       \n",
    "                _,loss_value = sess.run([contSolver, contLoss], feed_dict = feedDict)                        \n",
    "                # write logs at every iteration\n",
    "                #feedDict = {netTensors['inputs'][0]: xs, netTensors['inputs'][1][0]: inputData[0], netTensors['inputs'][1][1]: inputData[1], netTensors['dropoutVec']: [1] * len(dropoutVec), netTensors['targets'][0]: ys[:,10].reshape([batchSize,1]), netTensors['targets'][1]: ys[:,0:3]}                       \n",
    "                summary = merged_summary_op.eval(feed_dict=feedDict)\n",
    "                summary_writer.add_summary(summary, epoch * iterations + j)\n",
    "                print(\"  Train::: Epoch: %d, Step: %d, TotalSteps: %d, Loss: %g\" % (epoch, epoch * batchSize + j, steps, loss_value), cBranchesOutList[i])                        \n",
    "                if steps % 10 == 0: # clear_log\n",
    "                    clear_output(wait=True)\n",
    "                    \n",
    "                if steps % 50 == 0 and steps!=0: # batchSize\n",
    "                    print(j%50, '  Save Checkpoint ...')\n",
    "                    if not os.path.exists(modelPath):\n",
    "                        os.makedirs(modelPath)\n",
    "                    checkpoint_path = os.path.join(modelPath, \"model.ckpt\")\n",
    "                    filename = saver.save(sess, checkpoint_path)\n",
    "                    print(\"Model saved in file: %s\" % filename)                \n",
    "                    # update new Losses and Optimizers \n",
    "                    print('Initialize Variables in the Graph ...')\n",
    "                    # merge all summaries into a single op\n",
    "                    merged_summary_op = tf.summary.merge_all()\n",
    "                    sess.run(tf.global_variables_initializer())\n",
    "                    saver.restore(sess, \"test/model.ckpt\") # restore trained parameters\n",
    "\n",
    "                if steps % total_steps == 0 and steps!=0:\n",
    "                    # finish the training\n",
    "                    break\n",
    "            if steps % total_steps == 0 and steps!=0:\n",
    "                # finish the training\n",
    "                print('Finalize the training and Save Checkpoint ...')\n",
    "                if not os.path.exists(modelPath):\n",
    "                    os.makedirs(modelPath)\n",
    "                checkpoint_path = os.path.join(modelPath, \"model.ckpt\")\n",
    "                filename = saver.save(sess, checkpoint_path)\n",
    "                print(\"  Model saved in file: %s\" % filename)\n",
    "                break\n",
    "\n",
    "            tStopEpoch = time.time()\n",
    "            print( \"  Epoch Time Cost:\", round(tStopEpoch - tStartEpoch,2), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

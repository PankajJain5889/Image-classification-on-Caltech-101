{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\19706\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "from PIL import Image,ImageOps\n",
    "import PIL\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path += '\\\\101_ObjectCategories'\n",
    "contents = os.listdir(path)\n",
    "name_tags = {k: v for v, k in enumerate(contents)} # conver to dict of names:indices\n",
    "reverse_of_name_tags = {v: k for v, k in enumerate(contents)}# reverse dictionary for future use\\\n",
    "Data = []\n",
    "image_shape = (512 , 512)\n",
    "dropoutVec = [1.0] * 8 + [0.7] * 2 + [0.5] * 2 + [0.5] * 1 + [0.5, 1.] * 5\n",
    "learningRate=0.002\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "batchSize = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in contents: # read Data \n",
    "    folder_contents=os.listdir(path+\"\\\\\"+folder)\n",
    "    for file in folder_contents:\n",
    "        Data.append([path+\"\\\\\"+folder +\"\\\\\"+file , name_tags[folder]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate data \n",
    "X = [x[0] for x in Data]\n",
    "Y = [y[1] for y in Data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(range(total_files))\n",
    "random.shuffle(indices)\n",
    "train_indices = indices[:int(0.8*total_files)]\n",
    "test_indices = indices[int(0.8*total_files):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain = np.array([(X[i]) for i in train_indices]),np.array([Y[i] for i in train_indices]) \n",
    "Xtest,Ytest = np.array([X[i] for i in test_indices]),np.array([Y[i] for i in test_indices]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 267, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Xtrain[100]\n",
    "image = Image.open(image)\n",
    "image = np.array(image)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(inputs=Xtrain, targets = Ytrain , batchSize = 200):\n",
    "    batchX = np.zeros((batchSize, image_shape[0],image_shape[1],3 ))    \n",
    "    batchY = np.zeros((batchSize, 1))\n",
    "    idx = 0       \n",
    "    while True: # to make sure we never reach the end\n",
    "        counter = 0\n",
    "        while counter<=batchSize-1:\n",
    "            dataIdx = np.random.randint(batchSize-1) \n",
    "            file = inputs[dataIdx]\n",
    "            img = Image.open(file)\n",
    "            img = ImageOps.fit(img, image_shape, Image.ANTIALIAS)\n",
    "            image= np.array(img)\n",
    "            while image.shape != (image_shape[0],image_shape[1] ,3):\n",
    "                dataIdx = np.random.randint(batchSize-1) \n",
    "                file = inputs[dataIdx]\n",
    "                img = Image.open(file)\n",
    "                img = ImageOps.fit(img, image_shape, Image.ANTIALIAS)\n",
    "                image= np.array(img)\n",
    "            batchX[counter] = targets[dataIdx]    \n",
    "            batchY[counter] = targets[dataIdx]\n",
    "            counter += 1\n",
    "        yield (batchX, batchY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_ones(shape, name):\n",
    "    initial = tf.constant(1.0, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def weight_xavi_init(shape, name):\n",
    "    initial = tf.get_variable(name=name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return initial\n",
    "\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, dropout, image_shape):\n",
    "        \"\"\" We put a few counters to see how many times we called each function \"\"\"\n",
    "        self._dropout_vec = dropout\n",
    "        self._image_shape = image_shape\n",
    "        self._count_conv = 0\n",
    "        self._count_pool = 0\n",
    "        self._count_bn = 0\n",
    "        self._count_activations = 0\n",
    "        self._count_dropouts = 0\n",
    "        self._count_fc = 0\n",
    "        self._count_lstm = 0\n",
    "        self._count_soft_max = 0\n",
    "        self._conv_kernels = []\n",
    "        self._conv_strides = []\n",
    "        self._weights = {}\n",
    "        self._features = {}\n",
    "\n",
    "    \"\"\" Our conv is currently using bias \"\"\"\n",
    "\n",
    "    def conv(self, x, kernel_size, stride, output_size, padding_in='SAME'):\n",
    "        self._count_conv += 1\n",
    "\n",
    "        filters_in = x.get_shape()[-1]\n",
    "        shape = [kernel_size, kernel_size, filters_in, output_size]\n",
    "\n",
    "        weights = weight_xavi_init(shape, 'W_c_' + str(self._count_conv))\n",
    "        bias = bias_variable([output_size], name='B_c_' + str(self._count_conv))\n",
    "\n",
    "        self._weights['W_conv' + str(self._count_conv)] = weights\n",
    "        self._conv_kernels.append(kernel_size)\n",
    "        self._conv_strides.append(stride)\n",
    "\n",
    "        conv_res = tf.add(tf.nn.conv2d(x, weights, [1, stride, stride, 1], padding=padding_in,\n",
    "                                       name='conv2d_' + str(self._count_conv)), bias,\n",
    "                          name='add_' + str(self._count_conv))\n",
    "\n",
    "        self._features['conv_block' + str(self._count_conv - 1)] = conv_res\n",
    "\n",
    "        return conv_res\n",
    "\n",
    "    def max_pool(self, x, ksize=3, stride=2):\n",
    "        self._count_pool += 1\n",
    "        return tf.nn.max_pool(x, ksize=[1, ksize, ksize, 1], strides=[1, stride, stride, 1],\n",
    "                              padding='SAME', name='max_pool' + str(self._count_pool))\n",
    "\n",
    "    def bn(self, x):\n",
    "        self._count_bn += 1\n",
    "        return tf.contrib.layers.batch_norm(x, is_training=False,\n",
    "                                            updates_collections=None, scope='bn' + str(self._count_bn))\n",
    "\n",
    "    def activation(self, x):\n",
    "        self._count_activations += 1\n",
    "        return tf.nn.relu(x, name='relu' + str(self._count_activations))\n",
    "\n",
    "    def dropout(self, x):\n",
    "        print (\"Dropout\", self._count_dropouts)\n",
    "        self._count_dropouts += 1\n",
    "        output = tf.nn.dropout(x, self._dropout_vec[self._count_dropouts - 1],\n",
    "                               name='dropout' + str(self._count_dropouts))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def fc(self, x, output_size):\n",
    "        self._count_fc += 1\n",
    "        filters_in = x.get_shape()[-1]\n",
    "        shape = [filters_in, output_size]\n",
    "\n",
    "        weights = weight_xavi_init(shape, 'W_f_' + str(self._count_fc))\n",
    "        bias = bias_variable([output_size], name='B_f_' + str(self._count_fc))\n",
    "\n",
    "        return tf.nn.xw_plus_b(x, weights, bias, name='fc_' + str(self._count_fc))\n",
    "\n",
    "    def conv_block(self, x, kernel_size, stride, output_size, padding_in='SAME'):\n",
    "        print( \" === Conv\", self._count_conv, \"  :  \", kernel_size, stride, output_size)\n",
    "        with tf.name_scope(\"conv_block\" + str(self._count_conv)):\n",
    "            x = self.conv(x, kernel_size, stride, output_size, padding_in=padding_in)\n",
    "            x = self.bn(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            return self.activation(x)\n",
    "\n",
    "    def fc_block(self, x, output_size):\n",
    "        print (\" === FC\", self._count_fc, \"  :  \", output_size)\n",
    "        with tf.name_scope(\"fc\" + str(self._count_fc + 1)):\n",
    "            x = self.fc(x, output_size)\n",
    "            x = self.dropout(x)\n",
    "            self._features['fc_block' + str(self._count_fc + 1)] = x\n",
    "            return self.activation(x)\n",
    "\n",
    "    def get_weigths_dict(self):\n",
    "        return self._weights\n",
    "\n",
    "    def get_feat_tensors_dict(self):\n",
    "        return self._features\n",
    "def load_imitation_learning_network(input_image, dropout):\n",
    "    x = input_image\n",
    "    network_manager = Network(dropout, tf.shape(x))\n",
    "    with tf.name_scope(\"ConvNet\"):\n",
    "        \"\"\"conv1\"\"\"  # kernel sz, stride, num feature maps\n",
    "        xc = network_manager.conv_block(x, 5, 2, 32, padding_in='VALID')\n",
    "        print( xc)\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 32, padding_in='VALID')\n",
    "        print(xc)\n",
    "\n",
    "        \"\"\"conv2\"\"\"\n",
    "        xc = network_manager.conv_block(xc, 3, 2, 64, padding_in='VALID')\n",
    "        print(xc)\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 64, padding_in='VALID')\n",
    "        print(xc)\n",
    "\n",
    "        \"\"\"conv3\"\"\"\n",
    "        xc = network_manager.conv_block(xc, 3, 2, 128, padding_in='VALID')\n",
    "        print(xc)\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 128, padding_in='VALID')\n",
    "        print(xc)\n",
    "\n",
    "        \"\"\"conv4\"\"\"\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 256, padding_in='VALID')\n",
    "        print(xc)\n",
    "        xc = network_manager.conv_block(xc, 3, 1, 256, padding_in='VALID')\n",
    "        print(xc)\n",
    "        \"\"\"mp3 (default values)\"\"\"\n",
    "\n",
    "        \"\"\" reshape \"\"\"\n",
    "        x = tf.reshape(xc, [-1, int(np.prod(xc.get_shape()[1:]))], name='reshape')\n",
    "        print (x)\n",
    "\n",
    "        \"\"\" fc1 \"\"\"\n",
    "        x = network_manager.fc_block(x, 512)\n",
    "        print (x)\n",
    "        \"\"\" fc2 \"\"\"\n",
    "        x = network_manager.fc_block(x, 512)\n",
    "        \n",
    "        \"\"\"final layer\"\"\"\n",
    "        x = network_manager.fc_block(x , 256)\n",
    "        x = network_manager.fc_block(x , 256)\n",
    "        x = network_manager.fc_block(x , 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlNet(inputs, targets, shape, dropoutVec, scopeName = 'controlNET'):\n",
    "    \"\"\"\n",
    "        Get one image/sequence of images to predict control operations for controling the vehicle\n",
    "        inputs: N Batch of M images in order\n",
    "        shape: [BatchSize, SeqSize, FrameHeight, FrameWeight, Channels]\n",
    "        phase: placeholder for training\n",
    "        scopeName: TensorFlow Scope Name to separate nets in the graph\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scopeName) as scope:\n",
    "        with tf.name_scope(\"Network\"):           \n",
    "            networkTensor = load_imitation_learning_network(inputs, dropoutVec)\n",
    "            solverList = []\n",
    "            lossList = []\n",
    "            trainVars = tf.trainable_variables()\n",
    "            print(\"Network is up\" , networkTensor.shape , targets.shape)\n",
    "            with tf.name_scope(\"ConvNet\"):             \n",
    "                contLoss = tf.reduce_mean(tf.square(tf.subtract(networkTensor, targets))) #+ tf.add_n([tf.nn.l2_loss(v) for v in trainVars]) * L2NormConst\n",
    "                contSolver = tf.train.AdamOptimizer(learning_rate=learningRate, beta1=beta1,beta2=beta2).minimize(contLoss)\n",
    "                solverList.append(contSolver)\n",
    "                lossList.append(contLoss)  \n",
    "                tf.summary.scalar(\"ConVnet_output\", contLoss)        \n",
    "        tensors = {\n",
    "            'optimizers' : solverList,\n",
    "            'losses' : lossList,\n",
    "            'output' : networkTensor\n",
    "        }\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Net( prefSize=(image_shape[0], image_shape[1], 3)):   \n",
    "    shapeInput = [None, prefSize[0], prefSize[1], prefSize[2]]\n",
    "    inputImages = tf.placeholder(\"float\", shape=[None, prefSize[0], prefSize[1],prefSize[2]], name=\"input_image\")      \n",
    "    inputs = inputImages\n",
    "    dout = tf.placeholder(\"float\", shape=len(dropoutVec)) \n",
    "    targettag = tf.placeholder(tf.float32, shape=[None, 1], name=\"target_tag\")   \n",
    "    targets = targettag\n",
    "    print('Building ControlNet ...')    \n",
    "    controlOpTensors = controlNet(inputs, targets, shapeInput, dout,scopeName = 'controlNET')   \n",
    "    tensors = {\n",
    "            'inputs' : inputs,\n",
    "            'targets' : targets,\n",
    "            'dropoutVec' : dout,\n",
    "            'output' : controlOpTensors\n",
    "    }\n",
    "    return tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Net ...\n",
      "Building ControlNet ...\n",
      " === Conv 0   :   5 2 32\n",
      "Dropout 0\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block0/relu1:0\", shape=(?, 254, 254, 32), dtype=float32)\n",
      " === Conv 1   :   3 1 32\n",
      "Dropout 1\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block1/relu2:0\", shape=(?, 252, 252, 32), dtype=float32)\n",
      " === Conv 2   :   3 2 64\n",
      "Dropout 2\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block2/relu3:0\", shape=(?, 125, 125, 64), dtype=float32)\n",
      " === Conv 3   :   3 1 64\n",
      "Dropout 3\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block3/relu4:0\", shape=(?, 123, 123, 64), dtype=float32)\n",
      " === Conv 4   :   3 2 128\n",
      "Dropout 4\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block4/relu5:0\", shape=(?, 61, 61, 128), dtype=float32)\n",
      " === Conv 5   :   3 1 128\n",
      "Dropout 5\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block5/relu6:0\", shape=(?, 59, 59, 128), dtype=float32)\n",
      " === Conv 6   :   3 1 256\n",
      "Dropout 6\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block6/relu7:0\", shape=(?, 57, 57, 256), dtype=float32)\n",
      " === Conv 7   :   3 1 256\n",
      "Dropout 7\n",
      "Tensor(\"controlNET/Network/ConvNet/conv_block7/relu8:0\", shape=(?, 55, 55, 256), dtype=float32)\n",
      "Tensor(\"controlNET/Network/ConvNet/reshape:0\", shape=(?, 774400), dtype=float32)\n",
      " === FC 0   :   512\n",
      "Dropout 8\n",
      "Tensor(\"controlNET/Network/ConvNet/fc1/relu9:0\", shape=(?, 512), dtype=float32)\n",
      " === FC 1   :   512\n",
      "Dropout 9\n",
      " === FC 2   :   256\n",
      "Dropout 10\n",
      " === FC 3   :   256\n",
      "Dropout 11\n",
      " === FC 4   :   1\n",
      "Dropout 12\n",
      "Network is up (?, 1) (?, 1)\n",
      "{'optimizers': [<tf.Operation 'controlNET/Network/ConvNet_1/Adam' type=NoOp>], 'losses': [<tf.Tensor 'controlNET/Network/ConvNet_1/Mean:0' shape=() dtype=float32>], 'output': <tf.Tensor 'controlNET/Network/ConvNet/fc5/relu13:0' shape=(?, 1) dtype=float32>}\n",
      "Initialize Variables in the Graph ...\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sessGraph = tf.Graph()\n",
    "# GPU configuration\n",
    "memory_fraction = 0.75\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.visible_device_list = '0'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "tf.reset_default_graph()\n",
    "sessGraph = tf.Graph()\n",
    "# Prepare data generators\n",
    "batchListGenTrain = []\n",
    "#batchListGenVal = []\n",
    "#batchListName = []\n",
    "\n",
    "with tf.name_scope(\"ConvNet\"):\n",
    "    miniBatchGen = genData(Xtrain,Ytrain ,batchSize = batchSize)\n",
    "    batchListGenTrain.append(miniBatchGen)\n",
    "    #miniBatchGen = genData(Xval,Yval ,batchSize = batchSize)\n",
    "    #batchListGenVal.append(miniBatchGen)\n",
    "      \n",
    "with sessGraph.as_default():\n",
    "    sess = tf.Session(graph=sessGraph, config = config)\n",
    "    with sess.as_default():        \n",
    "        # build model\n",
    "        print('Building Net ...')\n",
    "        netTensors = Net(prefSize=(image_shape[0], image_shape[1], 3))\n",
    "        print(netTensors['output'])\n",
    "        print('Initialize Variables in the Graph ...')\n",
    "        sess.run(tf.global_variables_initializer()) # initialize variables       \n",
    "        # merge all summaries into a single op\n",
    "        merged_summary_op = tf.summary.merge_all()\n",
    "        saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V2)\n",
    "        if not(trainScratch):\n",
    "            saver.restore(sess, \"test/model.ckpt\") # restore trained parameters\n",
    "        # op to write logs to Tensorboard\n",
    "        logsPath = './logs'\n",
    "        modelPath = './test/'\n",
    "        summary_writer = tf.summary.FileWriter(logsPath, graph=sessGraph)\n",
    "        print('Start Training process ...')        \n",
    "        steps = 0\n",
    "        for epoch in range(epochs):\n",
    "            tStartEpoch = time.time()\n",
    "            print(\"Epoch:\", epoch)\n",
    "            iterations = Xtrain.shape[0]\n",
    "            for j in range(iterations):\n",
    "                steps += 1                \n",
    "                xs , ys = next(batchListGenTrain)                   \n",
    "                # augment images                    \n",
    "                contSolver = netTensors['output']['optimizers'][i]#solverList[i]\n",
    "                contLoss = netTensors['output']['losses'][i]#lossList[i]                                           \n",
    "                # [ inputs['inputImages','inputData'], targets['targetSpeed', 'targetController'],  'params', dropoutVec', output[optimizers, losses, branchesOutputs] ]\n",
    "                feedDict = {netTensors['inputs'][0]: xs,  netTensors['dropoutVec']: dropoutVec, \n",
    "                            netTensors['targets']: ys.reshape([batchSize,1]), \n",
    "                            }                       \n",
    "                _,loss_value = sess.run([contSolver, contLoss], feed_dict = feedDict)                        \n",
    "                # write logs at every iteration\n",
    "                #feedDict = {netTensors['inputs'][0]: xs, netTensors['inputs'][1][0]: inputData[0], netTensors['inputs'][1][1]: inputData[1], netTensors['dropoutVec']: [1] * len(dropoutVec), netTensors['targets'][0]: ys[:,10].reshape([batchSize,1]), netTensors['targets'][1]: ys[:,0:3]}                       \n",
    "                summary = merged_summary_op.eval(feed_dict=feedDict)\n",
    "                summary_writer.add_summary(summary, epoch * iterations + j)\n",
    "                print(\"  Train::: Epoch: %d, Step: %d, TotalSteps: %d, Loss: %g\" % (epoch, epoch * batchSize + j, steps, loss_value), cBranchesOutList[i])                        \n",
    "                if steps % 10 == 0: # clear_log\n",
    "                    clear_output(wait=True)\n",
    "                    \n",
    "                if steps % 50 == 0 and steps!=0: # batchSize\n",
    "                    print(j%50, '  Save Checkpoint ...')\n",
    "                    if not os.path.exists(modelPath):\n",
    "                        os.makedirs(modelPath)\n",
    "                    checkpoint_path = os.path.join(modelPath, \"model.ckpt\")\n",
    "                    filename = saver.save(sess, checkpoint_path)\n",
    "                    print(\"Model saved in file: %s\" % filename)                \n",
    "                    # update new Losses and Optimizers \n",
    "                    print('Initialize Variables in the Graph ...')\n",
    "                    # merge all summaries into a single op\n",
    "                    merged_summary_op = tf.summary.merge_all()\n",
    "                    sess.run(tf.global_variables_initializer())\n",
    "                    saver.restore(sess, \"test/model.ckpt\") # restore trained parameters\n",
    "\n",
    "                if steps % total_steps == 0 and steps!=0:\n",
    "                    # finish the training\n",
    "                    break\n",
    "            if steps % total_steps == 0 and steps!=0:\n",
    "                # finish the training\n",
    "                print('Finalize the training and Save Checkpoint ...')\n",
    "                if not os.path.exists(modelPath):\n",
    "                    os.makedirs(modelPath)\n",
    "                checkpoint_path = os.path.join(modelPath, \"model.ckpt\")\n",
    "                filename = saver.save(sess, checkpoint_path)\n",
    "                print(\"  Model saved in file: %s\" % filename)\n",
    "                break\n",
    "\n",
    "            tStopEpoch = time.time()\n",
    "            print( \"  Epoch Time Cost:\", round(tStopEpoch - tStartEpoch,2), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
